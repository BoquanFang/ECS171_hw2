{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ceeeb46",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "For this assignment, you will be developing an artificial neural network to classify data given in the __[Dry Beans Data Set](https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset#)__. This data set was obtained as a part of a research study by Selcuk University, Turkey, in which a computer vision system was developed to distinguish seven different registered varieties of dry beans with similar features. More details on the study can be found in the following __[research paper](https://www.sciencedirect.com/science/article/pii/S0168169919311573)__.\n",
    "\n",
    "## About the Data Set For Q1-2\n",
    "Seven different types of dry beans were used in a study in Selcuk University, Turkey, taking into account the features such as form, shape, type, and structure by the market situation. A computer vision system was developed to distinguish seven different registered varieties of dry beans with similar features in order to obtain uniform seed classification. For the classification model, images of 13611 grains of 7 different registered dry beans were taken with a high-resolution camera. Bean images obtained by computer vision system were subjected to segmentation and feature extraction stages, and a total of 16 features - 12 dimensions and 4 shape forms - were obtained from the grains.\n",
    "\n",
    "Number of Instances (records in the data set): __13611__\n",
    "\n",
    "Number of Attributes (fields within each record, including the class): __17__\n",
    "\n",
    "### Data Set Attribute Information:\n",
    "\n",
    "1. __Area (A)__ : The area of a bean zone and the number of pixels within its boundaries.\n",
    "2. __Perimeter (P)__ : Bean circumference is defined as the length of its border.\n",
    "3. __Major axis length (L)__ : The distance between the ends of the longest line that can be drawn from a bean.\n",
    "4. __Minor axis length (l)__ : The longest line that can be drawn from the bean while standing perpendicular to the main axis.\n",
    "5. __Aspect ratio (K)__ : Defines the relationship between L and l.\n",
    "6. __Eccentricity (Ec)__ : Eccentricity of the ellipse having the same moments as the region.\n",
    "7. __Convex area (C)__ : Number of pixels in the smallest convex polygon that can contain the area of a bean seed.\n",
    "8. __Equivalent diameter (Ed)__ : The diameter of a circle having the same area as a bean seed area.\n",
    "9. __Extent (Ex)__ : The ratio of the pixels in the bounding box to the bean area.\n",
    "10. __Solidity (S)__ : Also known as convexity. The ratio of the pixels in the convex shell to those found in beans.\n",
    "11. __Roundness (R)__ : Calculated with the following formula: (4piA)/(P^2)\n",
    "12. __Compactness (CO)__ : Measures the roundness of an object: Ed/L\n",
    "13. __ShapeFactor1 (SF1)__\n",
    "14. __ShapeFactor2 (SF2)__\n",
    "15. __ShapeFactor3 (SF3)__\n",
    "16. __ShapeFactor4 (SF4)__\n",
    "\n",
    "17. __Classes : *Seker, Barbunya, Bombay, Cali, Dermosan, Horoz, Sira*__\n",
    "\n",
    "### Libraries that can be used :\n",
    "- NumPy, SciPy, Pandas, Sci-Kit Learn, TensorFlow, Keras\n",
    "- Any other library used during the lectures and discussion sessions.\n",
    "\n",
    "## About the Data Set For Q3\n",
    "In this problem, we will be exploring the car dataset and analyzing their fuel efficiency. <br >\n",
    "Specifically, we will do some exploratory analysis with visualizations, then we will build a model for Simple Linear Regression, a model for Polynomial Regression, and one model for Logistic Regression. <br >\n",
    "**The given dataset is already modified and cleaned**, but you can find [the original information here.](https://archive.ics.uci.edu/ml/datasets/auto+mpg).\n",
    "\n",
    "## Dataset Attribute Information\n",
    "\n",
    "1. **mpg**: Miles per gallon. This is one primary measurement for car fuel efficiency.\n",
    "2. **displacement** : The cylinder volumes in cubic inches.\n",
    "3. **horsepower** : Engine power.\n",
    "4. **weight** : In pounds.\n",
    "5. **acceleration** : The elapsed time in seconds to go from 0 to 60mph.\n",
    "6. **origin** : Region of origin.\n",
    "\n",
    "### Libraries that can be used: numpy, pandas, scikit-learn, seaborn, plotly, matplotlib\n",
    "Any libraries used in the discussion materials are also allowed.\n",
    "\n",
    "\n",
    "### Other Notes\n",
    "- Don't worry about not being able to achieve high accuracy, it is neither the goal nor the grading standard of this assignment.\n",
    "- Discussion materials should be helpful for doing the assignments.\n",
    "- The homework submission should be a .ipynb file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264c751",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 1 : Building a Feed-Forward Neural Network(50 points in total)\n",
    "\n",
    "### Exercise 1.1 : Data Preprocessing (10 points)\n",
    "\n",
    "- As the classes are categorical, use one-hot encoding to represent the set of classes. You will find this useful when developing the output layer of the neural network.\n",
    "- Normalize each field of the input data using the min-max normalization technique.\n",
    "\n",
    "### Exercise 1.2 : Training and Testing the Neural Network (40 points)\n",
    "\n",
    "Design a 4-layer artificial neural network, specifically a feed-forward multi-layer perceptron (using the sigmoid activation function), to classify the type of 'Dry Bean' given the other attributes in the data set, similar to the one mentioned in the paper above. Please note that this is a multi-class classification problem so select the right number of nodes accordingly for the output layer.\n",
    "\n",
    "For training and testing the model, split the data into training and testing set by __90:10__ and use the training set for training the model and the test set to evaluate the model performance.\n",
    "\n",
    "Consider the following hyperparameters while developing your model :\n",
    "\n",
    "- Number of nodes in each hidden layer should be (12, 3)\n",
    "- Learning rate should be 0.3\n",
    "- Number of epochs should be 500\n",
    "- The sigmoid function should be used as the activation function in each layer\n",
    "- Stochastic Gradient Descent should be used to minimize the error rate\n",
    "\n",
    "__Requirements once the model has been trained :__\n",
    "\n",
    "- A confusion matrix for all classes, specifying the true positive, true negative, false positive, and false negative cases for each category in the class\n",
    "- The accuracy and mean squared error (MSE) of the model\n",
    "- The precision and recall for each label in the class\n",
    "\n",
    "__Notes :__\n",
    "\n",
    "- Splitting of the dataset should be done __after__ the data preprocessing step.\n",
    "- The mean squared error (MSE) values obtained __should be positive__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f3bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ac1572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset :\n",
      "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
      "0  44830    814.955       320.731947       178.405838      1.797766   \n",
      "1  33476    691.826       258.837971       165.220760      1.566619   \n",
      "2  27057    606.138       227.460904       151.860320      1.497830   \n",
      "3  49483    844.283       326.602913       194.689529      1.677558   \n",
      "4  22461    544.584       192.801303       148.541136      1.297966   \n",
      "\n",
      "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
      "0      0.831018       45297     238.912806  0.658877  0.989690   0.848226   \n",
      "1      0.769773       33907     206.453305  0.721155  0.987289   0.878921   \n",
      "2      0.744491       27358     185.607226  0.801831  0.988998   0.925436   \n",
      "3      0.802907       50289     251.005403  0.680179  0.983973   0.872348   \n",
      "4      0.637517       22699     169.110122  0.774731  0.989515   0.951720   \n",
      "\n",
      "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n",
      "0     0.744899      0.007154      0.001359      0.554874      0.997534   \n",
      "1     0.797616      0.007732      0.001930      0.636191      0.996669   \n",
      "2     0.815996      0.008407      0.002299      0.665850      0.997330   \n",
      "3     0.768534      0.006600      0.001420      0.590644      0.990840   \n",
      "4     0.877121      0.008584      0.003134      0.769342      0.998579   \n",
      "\n",
      "      Class  \n",
      "0      SIRA  \n",
      "1  DERMASON  \n",
      "2  DERMASON  \n",
      "3      SIRA  \n",
      "4  DERMASON  \n",
      "Class : \n",
      "['SIRA' 'DERMASON' 'BOMBAY' 'BARBUNYA' 'HOROZ' 'SEKER' 'CALI']\n",
      "Dimensions of the dataset :  (13611, 17)\n",
      "Features of the dataset :\n",
      "                 Area     Perimeter  MajorAxisLength  MinorAxisLength  \\\n",
      "count    13611.000000  13611.000000     13611.000000     13611.000000   \n",
      "unique            NaN           NaN              NaN              NaN   \n",
      "top               NaN           NaN              NaN              NaN   \n",
      "freq              NaN           NaN              NaN              NaN   \n",
      "mean     53048.284549    855.283459       320.141867       202.270714   \n",
      "std      29324.095717    214.289696        85.694186        44.970091   \n",
      "min      20420.000000    524.736000       183.601165       122.512653   \n",
      "25%      36328.000000    703.523500       253.303633       175.848170   \n",
      "50%      44652.000000    794.941000       296.883367       192.431733   \n",
      "75%      61332.000000    977.213000       376.495012       217.031741   \n",
      "max     254616.000000   1985.370000       738.860153       460.198497   \n",
      "\n",
      "        AspectRation  Eccentricity     ConvexArea  EquivDiameter  \\\n",
      "count   13611.000000  13611.000000   13611.000000   13611.000000   \n",
      "unique           NaN           NaN            NaN            NaN   \n",
      "top              NaN           NaN            NaN            NaN   \n",
      "freq             NaN           NaN            NaN            NaN   \n",
      "mean        1.583242      0.750895   53768.200206     253.064220   \n",
      "std         0.246678      0.092002   29774.915817      59.177120   \n",
      "min         1.024868      0.218951   20684.000000     161.243764   \n",
      "25%         1.432307      0.715928   36714.500000     215.068003   \n",
      "50%         1.551124      0.764441   45178.000000     238.438026   \n",
      "75%         1.707109      0.810466   62294.000000     279.446467   \n",
      "max         2.430306      0.911423  263261.000000     569.374358   \n",
      "\n",
      "              Extent      Solidity     roundness   Compactness  ShapeFactor1  \\\n",
      "count   13611.000000  13611.000000  13611.000000  13611.000000  13611.000000   \n",
      "unique           NaN           NaN           NaN           NaN           NaN   \n",
      "top              NaN           NaN           NaN           NaN           NaN   \n",
      "freq             NaN           NaN           NaN           NaN           NaN   \n",
      "mean        0.749733      0.987143      0.873282      0.799864      0.006564   \n",
      "std         0.049086      0.004660      0.059520      0.061713      0.001128   \n",
      "min         0.555315      0.919246      0.489618      0.640577      0.002778   \n",
      "25%         0.718634      0.985670      0.832096      0.762469      0.005900   \n",
      "50%         0.759859      0.988283      0.883157      0.801277      0.006645   \n",
      "75%         0.786851      0.990013      0.916869      0.834270      0.007271   \n",
      "max         0.866195      0.994677      0.990685      0.987303      0.010451   \n",
      "\n",
      "        ShapeFactor2  ShapeFactor3  ShapeFactor4     Class  \n",
      "count   13611.000000  13611.000000  13611.000000     13611  \n",
      "unique           NaN           NaN           NaN         7  \n",
      "top              NaN           NaN           NaN  DERMASON  \n",
      "freq             NaN           NaN           NaN      3546  \n",
      "mean        0.001716      0.643590      0.995063       NaN  \n",
      "std         0.000596      0.098996      0.004366       NaN  \n",
      "min         0.000564      0.410339      0.947687       NaN  \n",
      "25%         0.001154      0.581359      0.993703       NaN  \n",
      "50%         0.001694      0.642044      0.996386       NaN  \n",
      "75%         0.002170      0.696006      0.997883       NaN  \n",
      "max         0.003665      0.974767      0.999733       NaN  \n"
     ]
    }
   ],
   "source": [
    "# For question 1.1\n",
    "dataset = pd.read_csv(\"Dry_Beans_Dataset.csv\")\n",
    "\n",
    "print(\"Dataset :\")\n",
    "print(dataset.head())\n",
    "print(\"Class : \")\n",
    "print(dataset['Class'].unique())\n",
    "\n",
    "print(\"Dimensions of the dataset : \", dataset.shape)\n",
    "print(\"Features of the dataset :\")\n",
    "print(dataset.describe(include = 'all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3996715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            SIRA\n",
       "1        DERMASON\n",
       "2        DERMASON\n",
       "3            SIRA\n",
       "4        DERMASON\n",
       "           ...   \n",
       "13606    DERMASON\n",
       "13607      BOMBAY\n",
       "13608        SIRA\n",
       "13609       HOROZ\n",
       "13610        SIRA\n",
       "Name: Class, Length: 13611, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fea7f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed data :\n",
      "           Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
      "0      0.104229   0.198694         0.246967         0.165518      0.549934   \n",
      "1      0.055748   0.114396         0.135499         0.126473      0.385468   \n",
      "2      0.028340   0.055731         0.078990         0.086908      0.336523   \n",
      "3      0.124097   0.218773         0.257541         0.213740      0.464403   \n",
      "4      0.008715   0.013589         0.016569         0.077079      0.194315   \n",
      "...         ...        ...              ...              ...           ...   \n",
      "13606  0.083417   0.150914         0.162566         0.189677      0.315266   \n",
      "13607  0.646868   0.733202         0.747292         0.728031      0.426928   \n",
      "13608  0.118900   0.200327         0.218063         0.236224      0.342497   \n",
      "13609  0.097606   0.217940         0.274969         0.124833      0.723842   \n",
      "13610  0.112880   0.194735         0.214304         0.223307      0.358612   \n",
      "\n",
      "       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
      "0          0.883887    0.101465       0.190304  0.333127  0.933884   0.715687   \n",
      "1          0.795443    0.054511       0.110772  0.533453  0.902047   0.776947   \n",
      "2          0.758933    0.027513       0.059695  0.792964  0.924703   0.869780   \n",
      "3          0.843291    0.122044       0.219934  0.401647  0.858085   0.763829   \n",
      "4          0.604452    0.008307       0.019274  0.705791  0.931560   0.922235   \n",
      "...             ...         ...            ...       ...       ...        ...   \n",
      "13606      0.741008    0.081706       0.157567  0.774206  0.891199   0.827486   \n",
      "13607      0.822045    0.634805       0.751256  0.838477  0.861162   0.716156   \n",
      "13608      0.763728    0.115823       0.212324  0.810335  0.930870   0.834814   \n",
      "13609      0.942934    0.095347       0.180089  0.190594  0.908981   0.549951   \n",
      "13610      0.776173    0.110019       0.203386  0.551936  0.926158   0.817568   \n",
      "\n",
      "       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n",
      "0         0.300877      0.570351      0.256253      0.256074      0.957751  \n",
      "1         0.452920      0.645632      0.440609      0.400144      0.941143  \n",
      "2         0.505931      0.733560      0.559513      0.452690      0.953829  \n",
      "3         0.369044      0.498138      0.276116      0.319448      0.829136  \n",
      "4         0.682223      0.756639      0.828764      0.636047      0.977839  \n",
      "...            ...           ...           ...           ...           ...  \n",
      "13606     0.527803      0.531230      0.445374      0.474719      0.922317  \n",
      "13607     0.406893      0.091699      0.076613      0.355491      0.866564  \n",
      "13608     0.499111      0.460640      0.368388      0.445864      0.949738  \n",
      "13609     0.165785      0.650586      0.185084      0.136328      0.911521  \n",
      "13610     0.480530      0.479590      0.363443      0.427363      0.931075  \n",
      "\n",
      "[13611 rows x 16 columns]\n",
      "Pre-processed class :\n",
      "       BARBUNYA  BOMBAY  CALI  DERMASON  HOROZ  SEKER  SIRA\n",
      "0             0       0     0         0      0      0     1\n",
      "1             0       0     0         1      0      0     0\n",
      "2             0       0     0         1      0      0     0\n",
      "3             0       0     0         0      0      0     1\n",
      "4             0       0     0         1      0      0     0\n",
      "...         ...     ...   ...       ...    ...    ...   ...\n",
      "13606         0       0     0         1      0      0     0\n",
      "13607         0       1     0         0      0      0     0\n",
      "13608         0       0     0         0      0      0     1\n",
      "13609         0       0     0         0      1      0     0\n",
      "13610         0       0     0         0      0      0     1\n",
      "\n",
      "[13611 rows x 7 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, batch_size=100, hidden_layer_sizes=(12, 3),\n",
       "              learning_rate_init=0.3, max_iter=500, random_state=42,\n",
       "              solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, batch_size=100, hidden_layer_sizes=(12, 3),\n",
       "              learning_rate_init=0.3, max_iter=500, random_state=42,\n",
       "              solver=&#x27;sgd&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', batch_size=100, hidden_layer_sizes=(12, 3),\n",
       "              learning_rate_init=0.3, max_iter=500, random_state=42,\n",
       "              solver='sgd')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = dataset.drop('Class', axis = 1)\n",
    "y = dataset['Class']\n",
    "\n",
    "# normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_rescaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(data = X_rescaled, columns = X.columns)\n",
    "\n",
    "set_of_classes = y.value_counts().index.tolist()\n",
    "set_of_classes= pd.DataFrame({'Class': set_of_classes})\n",
    "y = pd.get_dummies(y)\n",
    "\n",
    "print(\"Pre-processed data :\")\n",
    "print(X)\n",
    "\n",
    "print(\"Pre-processed class :\")\n",
    "print(y)\n",
    "\n",
    "#splitting data into ratio 80:20\n",
    "data_train, data_test, class_train, class_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# Number of nodes in each hidden layer should be (10, 2)\n",
    "# Learning rate should be 0.4\n",
    "# Number of epochs should be 600\n",
    "mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.3, batch_size = 100, hidden_layer_sizes = (12, 3), max_iter = 500)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "325cfb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['Class']\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7965f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(data_train, class_train)\n",
    "\n",
    "pred = mlp.predict(data_test)\n",
    "pred\n",
    "#prediction on the test data. species are represented using the hot-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1a964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9023494860499266\n",
      "Mean Square Error :  0.02391441157960982\n",
      "[[0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1]]\n",
      "Confusion Matrix for each label : \n",
      "[[[1230    1]\n",
      "  [  16  115]]\n",
      "\n",
      " [[1310    0]\n",
      "  [   0   52]]\n",
      "\n",
      " [[1182   13]\n",
      "  [   5  162]]\n",
      "\n",
      " [[ 973   32]\n",
      "  [  39  318]]\n",
      "\n",
      " [[1150    7]\n",
      "  [  10  195]]\n",
      "\n",
      " [[1153    9]\n",
      "  [  20  180]]\n",
      "\n",
      " [[1073   39]\n",
      "  [  37  213]]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       131\n",
      "           1       1.00      1.00      1.00        52\n",
      "           2       0.93      0.97      0.95       167\n",
      "           3       0.91      0.89      0.90       357\n",
      "           4       0.97      0.95      0.96       205\n",
      "           5       0.95      0.90      0.93       200\n",
      "           6       0.85      0.85      0.85       250\n",
      "\n",
      "   micro avg       0.92      0.91      0.92      1362\n",
      "   macro avg       0.94      0.92      0.93      1362\n",
      "weighted avg       0.93      0.91      0.92      1362\n",
      " samples avg       0.93      0.91      0.91      1362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(class_test, pred))\n",
    "print(\"Mean Square Error : \", mean_squared_error(class_test, pred))\n",
    "\n",
    "print(pred[:5])\n",
    "print(\"Confusion Matrix for each label : \")\n",
    "cm = multilabel_confusion_matrix(class_test, pred)\n",
    "print(cm)\n",
    "\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(class_test, pred, zero_division = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d0a4ba",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "<img src=\"./matrix.png\" style=\"width:200px;height:200px\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f5188",
   "metadata": {},
   "source": [
    "## Exercise 2 : k-fold Cross Validation (10 points in total)\n",
    "\n",
    "In order to avoid using biased models, use 10-fold cross validation to generalize the model based on the given data set.\n",
    "\n",
    "__Requirements :__\n",
    "- The accuracy and MSE values during each iteration of the cross validation\n",
    "- The overall average accuracy and MSE value\n",
    "\n",
    "__Note :__ The mean squared error (MSE) values obtained should be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca5bf0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for batch  1  :  0.868575624082232\n",
      "Mean Square Error for batch  1  :  0.026117054751415986\n",
      "\n",
      "Accuracy for batch  2  :  0.9096252755326966\n",
      "Mean Square Error for batch  2  :  0.020258213498478006\n",
      "\n",
      "Accuracy for batch  3  :  0.9074210139603233\n",
      "Mean Square Error for batch  3  :  0.021937650886952872\n",
      "\n",
      "Accuracy for batch  4  :  0.9066862601028656\n",
      "Mean Square Error for batch  4  :  0.02183268605017319\n",
      "\n",
      "Accuracy for batch  5  :  0.9177075679647319\n",
      "Mean Square Error for batch  5  :  0.019838354151359296\n",
      "\n",
      "Accuracy for batch  6  :  0.9059515062454078\n",
      "Mean Square Error for batch  6  :  0.022252545397291906\n",
      "\n",
      "Accuracy for batch  7  :  0.9110947832476121\n",
      "Mean Square Error for batch  7  :  0.021727721213393513\n",
      "\n",
      "Accuracy for batch  8  :  0.9191770756796473\n",
      "Mean Square Error for batch  8  :  0.02015324866169833\n",
      "\n",
      "Accuracy for batch  9  :  0.8978692138133725\n",
      "Mean Square Error for batch  9  :  0.023931982785766772\n",
      "\n",
      "Accuracy for batch  10  :  0.9000734753857458\n",
      "Mean Square Error for batch  10  :  0.023512123438648055\n",
      "\n",
      "Average Accuracy =  0.9044181796014635\n",
      "Average MSE =  0.022156158083517792\n"
     ]
    }
   ],
   "source": [
    "# To find list of accuracy and MSE values\n",
    "# Without using the sklearn function cross_validate()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_splits=10\n",
    "# step 1: randomize the dataset and create k equal size partitions\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "acc = 0\n",
    "mse = 0\n",
    "\n",
    "i = 0 #keep track of batch number\n",
    "# step 5: iterate k times with a different testing subset\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "\n",
    "    # step 2-3: use k-1/k^th partition for the training/testing model\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\n",
    "    \n",
    "    # perform the training similar to Q1\n",
    "    #this was based on the requirements in Q1\n",
    "    mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.3, batch_size = 100, hidden_layer_sizes = (12, 3), max_iter = 500)\n",
    "    mlp.fit(X[start_train:stop_train], y[start_train:stop_train])\n",
    "    pred = mlp.predict(X[start_test:stop_test])\n",
    "    \n",
    "    # step 4: record the evaluating scores\n",
    "    i+=1\n",
    "    acc += accuracy_score(y[start_test:stop_test], pred)\n",
    "    mse += mean_squared_error(y[start_test:stop_test], pred)\n",
    "    \n",
    "    print(\"\\nAccuracy for batch \", i, \" : \", accuracy_score(y[start_test:stop_test], pred))\n",
    "    print(\"Mean Square Error for batch \", i, \" : \", mean_squared_error(y[start_test:stop_test], pred))\n",
    "\n",
    "# step 6: find the average and select the batch with highest evaluation scores\n",
    "print('\\nAverage Accuracy = ', acc / n_splits)\n",
    "print('Average MSE = ', mse / n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7491c1",
   "metadata": {},
   "source": [
    "## Exercise 3 - Logistic Regression (20 points in total)\n",
    "Recall the dataset from last week homework\n",
    "\n",
    "Now we are going to build a classification model on ``origin`` using all the other 5 attributes. <br >\n",
    "Note that Logistic Regression is a binary classificaiton algorithm.\n",
    "\n",
    "### Exercise 3.1 - Processing and Splitting the Dataset (5 points)\n",
    "In this exercise 3, we only consider those observations where they originate from either \"USA\" or \"Japan\". <br >\n",
    "So please **remove** those observations that originate from \"Europe\". <br >\n",
    "And then, split the data into training and testing set with the ratio of 80:20. <br >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed1574cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./auto-mpg.csv')\n",
    "\n",
    "data = df.copy().loc[(df['origin'] != 'Europe'), :]\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=21)\n",
    "# The remaining\n",
    "X_train, y_train = train.drop(columns=['origin']) ,train['origin']\n",
    "X_test, y_test = test.drop(columns=['origin']), test['origin']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89374dbf",
   "metadata": {},
   "source": [
    "### Exercise 3.2 - Logistic Regression (15 points)\n",
    "\n",
    "Using all the other 5 attributes, please build a Logistic Regression model that distinguishes between cars from Japan and cars from the USA. <br >\n",
    "Then, **if we are distinguishing between Japan and Europe this time, how do you think the model performance(in terms of accuracy) will change? Provide your reasoning.** (Hint: Exercise 1)\n",
    "\n",
    "Requirements\n",
    " - Report the testing precision and recall for both regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74828168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Japan       0.81      0.62      0.70        21\n",
      "         USA       0.84      0.93      0.88        44\n",
      "\n",
      "    accuracy                           0.83        65\n",
      "   macro avg       0.82      0.78      0.79        65\n",
      "weighted avg       0.83      0.83      0.82        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cls = LogisticRegression()\n",
    "cls.fit(X_train, y_train)\n",
    "print(classification_report(y_test, cls.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98465106",
   "metadata": {},
   "source": [
    "If we want to distinguish between Japan and Europe, the accuracy will decrease. The logistic regression is for the model to find the distinction between data. If data points from different categorical values are more separated, then logistic regression will perform better than they did for data points which are overlapping with each other. When we refer to the pairplot of exercise 1, we can find the green dots which represents Europe and orange plot which represents Japan are overlapping with each other. Therefore, it will be difficult for logistic regression to distinguish those points and the accuracy will decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f7416",
   "metadata": {},
   "source": [
    "## Exercise 4 - Polynomial Regressor using Gradient Descent (20 points in total)\n",
    "Now we are going to look into model fitting. In the dataset cost.csv, the first column is the independent variable cost, and the second column is the dependent variable production_output.\n",
    "\n",
    "### Exercise 4.1 - Split the dataset (5 points)\n",
    "Import the dataset cost.csv and split them into training and testing set with ratio 70:30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e9fa803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\26366\\AppData\\Local\\Temp\\ipykernel_21500\\2237134197.py:5: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  X_train = X_train[:, np.newaxis]\n",
      "C:\\Users\\26366\\AppData\\Local\\Temp\\ipykernel_21500\\2237134197.py:6: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  y_train = y_train[:, np.newaxis]\n",
      "C:\\Users\\26366\\AppData\\Local\\Temp\\ipykernel_21500\\2237134197.py:7: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  X_test = X_test[:, np.newaxis]\n",
      "C:\\Users\\26366\\AppData\\Local\\Temp\\ipykernel_21500\\2237134197.py:8: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  y_test = y_test[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./cost.csv')\n",
    "train, test = train_test_split(df, test_size=0.3, random_state=21)\n",
    "X_train, y_train = train['cost'], train['production_output']\n",
    "X_test, y_test  = test['cost'], test['production_output']\n",
    "X_train = X_train[:, np.newaxis]\n",
    "y_train = y_train[:, np.newaxis]\n",
    "X_test = X_test[:, np.newaxis]\n",
    "y_test = y_test[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531d7f98",
   "metadata": {},
   "source": [
    "### Exercise 4.2 - Polynomial Regression (15 points)\n",
    "Compute the RMSE and R2 for the training and testing set. Using polynomial regression with degree 1, 2, 3, and 4, which model provides the most appropriate prediction? Justify your answer and plot the models fitted line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "acdf0cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "857b3040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RMSE: 0.473207563340723\n",
      "Training R2: 0.660108476969875\n",
      "\n",
      "Test RMSE: 0.666092218912199\n",
      "Test R2: 0.250945501489915\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For degree one, it is the same as linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train,y_train_pred))\n",
    "r2 = r2_score(y_train,y_train_pred)\n",
    "print('\\nTraining RMSE: %8.15f' % rmse)\n",
    "print('Training R2: %8.15f' % r2)\n",
    "\n",
    "# Reporting for the test set:\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test,y_test_pred))\n",
    "r2_test = r2_score(y_test,y_test_pred)\n",
    "print('\\nTest RMSE: %8.15f' % rmse_test)\n",
    "print('Test R2: %8.15f' % r2_test)\n",
    "\n",
    "\n",
    "# sort the values of x before line plot\n",
    "# sort_axis = operator.itemgetter(0)\n",
    "# sorted_zip = sorted(zip(X_train,y_train_pred), key=sort_axis)\n",
    "# X_train, y_train_pred = zip(*sorted_zip)\n",
    "\n",
    "plt.scatter(X_train, y_train, s=10)\n",
    "plt.plot(X_train, y_train_pred, color='m')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f5edd987",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'asarry'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m x_poly_test \u001b[38;5;241m=\u001b[39m polynomial_features\u001b[38;5;241m.\u001b[39mfit_transform(X_test) \n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m----> 7\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_poly_train, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarry\u001b[49m(y_train)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      8\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_poly_train)\n\u001b[0;32m      9\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_poly_test)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\__init__.py:311\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    312\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'asarry'"
     ]
    }
   ],
   "source": [
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "\n",
    "x_poly_train = polynomial_features.fit_transform(X_train) \n",
    "x_poly_test = polynomial_features.fit_transform(X_test) \n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_poly_train, np.asarray(y_train).reshape(-1,1))\n",
    "y_train_pred = model.predict(x_poly_train)\n",
    "y_test_pred = model.predict(x_poly_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train,y_train_pred))\n",
    "r2 = r2_score(y_train,y_train_pred)\n",
    "print('\\nTraining RMSE: %8.15f' % rmse)\n",
    "print('Training R2: %8.15f' % r2)\n",
    "\n",
    "# Reporting for the test set:\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test,y_test_pred))\n",
    "r2_test = r2_score(y_test,y_test_pred)\n",
    "print('\\nTest RMSE: %8.15f' % rmse_test)\n",
    "print('Test R2: %8.15f' % r2_test)\n",
    "\n",
    "\n",
    "plt.scatter(x_poly_train, polynomial_features.fit_transform(y_train), s=10)\n",
    "# sort the values of x before line plot\n",
    "# sort_axis = operator.itemgetter(0)\n",
    "# sorted_zip = sorted(zip(X_train,y_train_pred), key=sort_axis)\n",
    "# X_train, y_train_pred = zip(*sorted_zip)\n",
    "plt.plot(x_poly_train, y_train_pred, color='m')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d14ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
